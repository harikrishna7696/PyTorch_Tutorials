{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import the required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#=======================================================#\n",
        "#           Download and Load the Dataset               #\n",
        "#=======================================================#\n",
        "train_data = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "test_data = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "#=======================================================#\n",
        "#           Parameters to use while training            #\n",
        "#=======================================================#\n",
        "input_size = 28 * 28\n",
        "num_classes = 10\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "#=====================================================================================#\n",
        "#          Load into DataLoader Which will make easire to access and train            #\n",
        "#=====================================================================================#\n",
        "\n",
        "# dataloaders will shuffle and split into batches and create iterators\n",
        "train_data_loader =DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "test_data_loader =DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# create the model\n",
        "model = nn.Linear(input_size, num_classes)\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# model optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "# iterating the throught the network\n",
        "for i in range(num_epochs):\n",
        "  for batch, (train_images, train_labels) in enumerate(train_data_loader):\n",
        "\n",
        "    # flattening the image from 28 * 28 to 784\n",
        "    train_images = train_images.reshape(-1, input_size)\n",
        "    # passing the flatten image to model\n",
        "    output = model(train_images)\n",
        "    # calculating the loss between predicted and actual ground truths\n",
        "    loss = criterion(output, train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # backward propagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"epoch: {i}, batch: {batch}, loss: {loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0VzmeMmmOB2",
        "outputId": "5ad458cc-9b1e-448c-cc38-82c4ba8979c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, batch: 937, loss: 0.3805159032344818\n",
            "epoch: 1, batch: 937, loss: 0.0816948264837265\n",
            "epoch: 2, batch: 937, loss: 0.3752652406692505\n",
            "epoch: 3, batch: 937, loss: 0.2628442645072937\n",
            "epoch: 4, batch: 937, loss: 0.4250142574310303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtotal_labels = 0\n",
        "correct_detected = 0\n",
        "\n",
        "# testing the model\n",
        "for test_images, test_labels in test_data_loader:\n",
        "  test_images = test_images.reshape(-1, input_size)\n",
        "  model_outputs = model(test_images)\n",
        "  _, predicted = torch.max(model_outputs.data, -1)\n",
        "  total_labels = predicted.size(0)\n",
        "  correct_detected = (test_labels == predicted).sum()\n",
        "print(f\"model accuracy, {(correct_detected/total_labels)*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VOSXYjBs3Xh",
        "outputId": "e0e0c835-c02d-4e42-8299-3ffa98072f6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy, 93.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "torch.save(model.state_dict(), \"model.ckpt\")"
      ],
      "metadata": {
        "id": "L1F72Lc4ubUa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS9bohlcuje0",
        "outputId": "ac7cb832-4dd0-43fd-e148-391285f2ed4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ 0.0345,  0.0191,  0.0031,  ..., -0.0050,  0.0101,  0.0163],\n",
              "                      [ 0.0284, -0.0345,  0.0088,  ..., -0.0078,  0.0103, -0.0354],\n",
              "                      [ 0.0221,  0.0078,  0.0123,  ..., -0.0309,  0.0095,  0.0126],\n",
              "                      ...,\n",
              "                      [-0.0123, -0.0065,  0.0026,  ...,  0.0280,  0.0203, -0.0198],\n",
              "                      [-0.0233, -0.0168,  0.0167,  ...,  0.0263,  0.0324,  0.0061],\n",
              "                      [ 0.0323, -0.0209,  0.0338,  ...,  0.0306,  0.0342, -0.0202]])),\n",
              "             ('bias',\n",
              "              tensor([-0.2920,  0.3931,  0.0362, -0.2331,  0.1063,  0.6721, -0.0801,  0.3640,\n",
              "                      -0.8345, -0.1194]))])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}